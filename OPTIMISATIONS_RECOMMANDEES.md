# Optimisations Recommand√©es - Syst√®me d'Archivage C.E.R.E.R

Liste prioris√©e des optimisations pour am√©liorer les performances et la capacit√©.

---

## üéØ Optimisations Prioritaires (√Ä faire AVANT le d√©ploiement)

### 1. Ajuster le Rate Limiting ‚≠ê‚≠ê‚≠ê (CRITIQUE)

**Probl√®me actuel :** 100 requ√™tes/15min trop restrictif pour un campus universitaire.

**Solution :**

```javascript
// Dans security-config.js

// AVANT (actuel)
const generalLimiter = rateLimit({
    windowMs: 15 * 60 * 1000,
    max: 100  // ‚ùå Trop restrictif
});

// APR√àS (recommand√©)
const generalLimiter = rateLimit({
    windowMs: 15 * 60 * 1000,
    max: 500,  // ‚úÖ Plus adapt√© pour un campus
    message: 'Trop de requ√™tes. Veuillez r√©essayer dans 15 minutes.'
});

const uploadLimiter = rateLimit({
    windowMs: 60 * 60 * 1000,
    max: 50,  // ‚úÖ Augment√© de 10 √† 50
    message: 'Trop d\'uploads. R√©essayez dans 1 heure.'
});
```

**Impact :** +400% de capacit√© pour les utilisateurs sur le m√™me r√©seau

**Effort :** 5 minutes ‚è±Ô∏è

---

### 2. Augmenter le TTL des Sessions ‚≠ê‚≠ê (IMPORTANT)

**Probl√®me actuel :** Sessions expirent apr√®s 1h ‚Üí reconnexions fr√©quentes.

**Solution :**

```javascript
// Dans server.js (ligne ~303)

// AVANT (actuel)
store: MongoStore.create({
    // ...
    ttl: 3600,  // ‚ùå 1 heure
    touchAfter: 60
}),

// APR√àS (recommand√©)
store: MongoStore.create({
    // ...
    ttl: 86400,  // ‚úÖ 24 heures (1 jour)
    touchAfter: 300  // ‚úÖ Mise √† jour toutes les 5 minutes
}),
```

**Impact :** Meilleure exp√©rience utilisateur, -80% de requ√™tes d'authentification

**Effort :** 2 minutes ‚è±Ô∏è

---

### 3. Configurer PM2 en mode Cluster ‚≠ê‚≠ê‚≠ê (IMPORTANT)

**D√©j√† fait :** ‚úÖ Fichier `ecosystem.config.js` cr√©√© avec 2 instances.

**V√©rifier la configuration :**

```javascript
// Dans ecosystem.config.js
module.exports = {
  apps: [{
    name: 'archivage-cerer',
    script: './server.js',
    instances: 2,  // ‚úÖ Ajuster selon les CPU (CPU/2)
    exec_mode: 'cluster'
  }]
};
```

**Pour un serveur 4 CPU :** `instances: 2`
**Pour un serveur 8 CPU :** `instances: 4`

**Impact :** +100% de capacit√©, haute disponibilit√©

**Effort :** 0 minutes (d√©j√† configur√©) ‚è±Ô∏è

---

## üöÄ Optimisations Court Terme (1-3 mois)

### 4. Impl√©menter un Cache Redis ‚≠ê‚≠ê‚≠ê (HAUTE PRIORIT√â)

**Pourquoi :** R√©duire la charge MongoDB et am√©liorer les temps de r√©ponse.

**Installation :**

```bash
# Sur le serveur
sudo apt install redis-server -y
sudo systemctl start redis
sudo systemctl enable redis

# Dans le projet
npm install redis
```

**Impl√©mentation :**

```javascript
// Cr√©er cache-manager.js
const redis = require('redis');
const client = redis.createClient({
    host: 'localhost',
    port: 6379
});

client.connect();

// Fonctions de cache
async function cacheGet(key) {
    const data = await client.get(key);
    return data ? JSON.parse(data) : null;
}

async function cacheSet(key, value, ttl = 3600) {
    await client.setEx(key, ttl, JSON.stringify(value));
}

async function cacheDel(key) {
    await client.del(key);
}

module.exports = { cacheGet, cacheSet, cacheDel, client };
```

**Utilisation :**

```javascript
// Exemple : Cache des r√¥les
const { cacheGet, cacheSet } = require('./cache-manager');

async function getRole(roleId) {
    // 1. V√©rifier le cache
    const cacheKey = `role:${roleId}`;
    const cached = await cacheGet(cacheKey);
    if (cached) {
        console.log('‚úÖ Cache hit:', cacheKey);
        return cached;
    }

    // 2. Si pas en cache, r√©cup√©rer de MongoDB
    const role = await rolesCollection.findOne({ _id: roleId });

    // 3. Mettre en cache (TTL: 1h)
    if (role) {
        await cacheSet(cacheKey, role, 3600);
    }

    return role;
}
```

**Donn√©es √† cacher (par priorit√©) :**

1. ‚úÖ **R√¥les** (rarement modifi√©s, souvent lus)
2. ‚úÖ **D√©partements** (rarement modifi√©s)
3. ‚úÖ **Cat√©gories** (rarement modifi√©es)
4. ‚úÖ **Listes de documents** (cache 5 minutes)
5. ‚úÖ **R√©sultats de recherche** (cache 10 minutes)

**Impact :**
- -30% charge MongoDB
- -40% temps de r√©ponse
- +50% requ√™tes/seconde

**Effort :** 1-2 jours de d√©veloppement ‚è±Ô∏è

---

### 5. Mettre en place Cloudflare (CDN) ‚≠ê‚≠ê (MOYEN)

**Pourquoi :** Acc√©l√©rer le chargement des fichiers statiques et r√©duire la bande passante.

**Configuration :**

1. **Cr√©er un compte Cloudflare** (gratuit) : https://cloudflare.com
2. **Ajouter votre domaine** : `archivage.ucad.sn`
3. **Changer les DNS** : Pointer vers Cloudflare
4. **Activer :**
   - ‚úÖ Auto Minify (HTML, CSS, JS)
   - ‚úÖ Brotli compression
   - ‚úÖ Caching level: Standard
   - ‚úÖ Browser Cache TTL: 4 hours

**Dans Nginx :**

```nginx
# Ajouter des headers pour Cloudflare
location /public {
    alias /home/cerer/apps/archivage-cerer/backend/public;
    expires 7d;
    add_header Cache-Control "public, immutable";
    add_header X-Content-Type-Options "nosniff";
}
```

**Impact :**
- -60% bande passante serveur
- Temps de chargement divis√© par 2-3
- Protection DDoS gratuite

**Effort :** 1-2 heures ‚è±Ô∏è

---

### 6. Optimiser les Index MongoDB ‚≠ê‚≠ê (MOYEN)

**V√©rifier les index existants :**

```javascript
// Dans MongoDB shell ou script
await documentsCollection.getIndexes();
await usersCollection.getIndexes();
```

**Index actuels (d√©j√† bien configur√©s) :**

```javascript
// ‚úÖ D√©j√† pr√©sents
await documentsCollection.createIndex({ idDocument: 1 });
await documentsCollection.createIndex({ idDepartement: 1 });
await usersCollection.createIndex({ username: 1 }, { unique: true });
await usersCollection.createIndex({ email: 1 }, { unique: true });
```

**Index suppl√©mentaires recommand√©s :**

```javascript
// Pour les recherches par titre
await documentsCollection.createIndex({ titre: 'text' });

// Pour les recherches par date
await documentsCollection.createIndex({ dateCreation: -1 });

// Pour les filtres combin√©s
await documentsCollection.createIndex({ idDepartement: 1, dateCreation: -1 });

// Pour les recherches d'utilisateurs par d√©partement
await usersCollection.createIndex({ idDepartement: 1 });
```

**Impact :** -50% temps de recherche

**Effort :** 30 minutes ‚è±Ô∏è

---

## üîß Optimisations Moyen Terme (3-6 mois)

### 7. Queue d'Upload Asynchrone ‚≠ê‚≠ê‚≠ê (HAUTE PRIORIT√â)

**Pourquoi :** Les uploads bloquent le serveur Node.js.

**Solution : Bull (queue bas√©e sur Redis)**

```bash
npm install bull
```

**Configuration :**

```javascript
// upload-queue.js
const Bull = require('bull');

const uploadQueue = new Bull('file-uploads', {
    redis: {
        host: 'localhost',
        port: 6379
    }
});

// Processor
uploadQueue.process(async (job) => {
    const { file, userId, metadata } = job.data;

    console.log(`üì§ Processing upload for ${userId}: ${file.name}`);

    // 1. Sauvegarder le fichier
    await saveFile(file);

    // 2. Cr√©er l'entr√©e en base
    await documentsCollection.insertOne({
        ...metadata,
        userId,
        fileName: file.name,
        uploadDate: new Date()
    });

    // 3. Mettre √† jour le statut
    job.progress(100);

    return { success: true };
});

module.exports = uploadQueue;
```

**Utilisation dans l'API :**

```javascript
const uploadQueue = require('./upload-queue');

app.post('/api/upload', async (req, res) => {
    // Ajouter √† la queue au lieu de traiter imm√©diatement
    const job = await uploadQueue.add({
        file: req.file,
        userId: req.session.userId,
        metadata: req.body
    });

    // R√©pondre imm√©diatement
    res.json({
        success: true,
        jobId: job.id,
        message: 'Upload en cours de traitement'
    });
});

// Endpoint pour v√©rifier le statut
app.get('/api/upload/:jobId/status', async (req, res) => {
    const job = await uploadQueue.getJob(req.params.jobId);
    res.json({
        status: await job.getState(),
        progress: job.progress()
    });
});
```

**Impact :**
- Uploads non-bloquants
- +200% uploads simultan√©s possibles
- Meilleure exp√©rience utilisateur

**Effort :** 2-3 jours ‚è±Ô∏è

---

### 8. Pagination Optimis√©e ‚≠ê‚≠ê (MOYEN)

**Probl√®me actuel :** R√©cup√©rer tous les documents puis paginer en JavaScript.

**Solution : Pagination MongoDB native**

```javascript
// AVANT (non optimal)
app.get('/api/documents', async (req, res) => {
    const allDocs = await documentsCollection.find({}).toArray();
    const page = parseInt(req.query.page) || 1;
    const limit = 20;
    const start = (page - 1) * limit;

    res.json(allDocs.slice(start, start + limit));  // ‚ùå Inefficace
});

// APR√àS (optimis√©)
app.get('/api/documents', async (req, res) => {
    const page = parseInt(req.query.page) || 1;
    const limit = 20;
    const skip = (page - 1) * limit;

    const [documents, total] = await Promise.all([
        documentsCollection.find({})
            .skip(skip)
            .limit(limit)
            .toArray(),
        documentsCollection.countDocuments({})
    ]);

    res.json({
        documents,
        page,
        totalPages: Math.ceil(total / limit),
        total
    });
});
```

**Impact :** -70% utilisation m√©moire, -80% temps de r√©ponse

**Effort :** 1 jour ‚è±Ô∏è

---

### 9. Compression d'Images Automatique ‚≠ê (FAIBLE)

**Pourquoi :** R√©duire l'espace de stockage et la bande passante.

**Solution : Sharp (biblioth√®que de traitement d'image)**

```bash
npm install sharp
```

**Impl√©mentation :**

```javascript
const sharp = require('sharp');

async function compressImage(inputPath, outputPath) {
    await sharp(inputPath)
        .resize(1920, 1080, { fit: 'inside', withoutEnlargement: true })
        .jpeg({ quality: 80 })
        .toFile(outputPath);
}

// Dans l'endpoint upload
if (file.mimetype.startsWith('image/')) {
    await compressImage(file.path, file.path);
}
```

**Impact :** -60% taille des images, √©conomies de stockage

**Effort :** 1 jour ‚è±Ô∏è

---

## üéØ Optimisations Long Terme (6-12 mois)

### 10. Load Balancer (si > 5000 utilisateurs/jour) ‚≠ê‚≠ê‚≠ê

**Configuration avec Nginx :**

```nginx
# load-balancer.conf
upstream backend {
    least_conn;  # M√©thode de distribution
    server 192.168.1.10:4000 weight=1;
    server 192.168.1.11:4000 weight=1;
    server 192.168.1.12:4000 weight=1;
}

server {
    listen 443 ssl;
    server_name archivage.ucad.sn;

    location / {
        proxy_pass http://backend;
        # ...
    }
}
```

**Impact :** Capacit√© multipli√©e par le nombre de serveurs

**Effort :** 1 semaine (configuration + tests) ‚è±Ô∏è

---

### 11. ElasticSearch pour Recherche Full-Text ‚≠ê‚≠ê

**Pourquoi :** Recherche beaucoup plus rapide et pertinente.

**Configuration :**

```bash
# Installation
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.11.0-amd64.deb
sudo dpkg -i elasticsearch-8.11.0-amd64.deb
sudo systemctl start elasticsearch
```

**Synchronisation MongoDB ‚Üí ElasticSearch :**

```javascript
const { Client } = require('@elastic/elasticsearch');
const esClient = new Client({ node: 'http://localhost:9200' });

// Indexer un document
async function indexDocument(doc) {
    await esClient.index({
        index: 'documents',
        id: doc._id.toString(),
        body: {
            titre: doc.titre,
            contenu: doc.contenu,
            dateCreation: doc.dateCreation
        }
    });
}

// Rechercher
async function searchDocuments(query) {
    const result = await esClient.search({
        index: 'documents',
        body: {
            query: {
                multi_match: {
                    query,
                    fields: ['titre^2', 'contenu']
                }
            }
        }
    });

    return result.hits.hits.map(hit => hit._source);
}
```

**Impact :** Recherche 10x plus rapide

**Effort :** 1-2 semaines ‚è±Ô∏è

---

## üìä Tableau R√©capitulatif

| Optimisation | Priorit√© | Impact | Effort | Quand |
|--------------|----------|--------|--------|-------|
| **Rate Limiting** | ‚≠ê‚≠ê‚≠ê | +400% capacit√© | 5 min | AVANT d√©ploiement |
| **TTL Sessions** | ‚≠ê‚≠ê | -80% auth | 2 min | AVANT d√©ploiement |
| **PM2 Cluster** | ‚≠ê‚≠ê‚≠ê | +100% capacit√© | 0 min | ‚úÖ D√©j√† fait |
| **Cache Redis** | ‚≠ê‚≠ê‚≠ê | -40% latence | 1-2 jours | 1-3 mois |
| **CDN Cloudflare** | ‚≠ê‚≠ê | -60% bande passante | 1-2h | 1-3 mois |
| **Index MongoDB** | ‚≠ê‚≠ê | -50% recherche | 30 min | 1-3 mois |
| **Queue Upload** | ‚≠ê‚≠ê‚≠ê | +200% uploads | 2-3 jours | 3-6 mois |
| **Pagination** | ‚≠ê‚≠ê | -70% m√©moire | 1 jour | 3-6 mois |
| **Compression Images** | ‚≠ê | -60% stockage | 1 jour | 3-6 mois |
| **Load Balancer** | ‚≠ê‚≠ê‚≠ê | +200-300% | 1 semaine | 6-12 mois |
| **ElasticSearch** | ‚≠ê‚≠ê | 10x recherche | 1-2 semaines | 6-12 mois |

---

## ‚úÖ Checklist d'impl√©mentation

### Avant le d√©ploiement (√Ä faire maintenant)

- [ ] Augmenter rate limiting √† 500 req/15min
- [ ] Augmenter TTL sessions √† 24h
- [ ] V√©rifier PM2 cluster configur√© (2-4 instances)
- [ ] Tester avec 50-100 utilisateurs simul√©s

### 1-3 mois apr√®s d√©ploiement

- [ ] Installer Redis
- [ ] Impl√©menter cache pour r√¥les/d√©partements
- [ ] Configurer Cloudflare CDN
- [ ] Ajouter index MongoDB suppl√©mentaires
- [ ] Monitoring actif (PM2 Plus ou Datadog)

### 3-6 mois (si besoin)

- [ ] Queue Bull pour uploads
- [ ] Pagination MongoDB native
- [ ] Compression d'images automatique
- [ ] Tests de charge r√©guliers

### 6-12 mois (si forte croissance)

- [ ] Load balancer
- [ ] ElasticSearch
- [ ] Microservices (auth, upload, search s√©par√©s)

---

## üéØ Conclusion

**Actions imm√©diates (5 minutes) :**
1. Rate limiting : 100 ‚Üí 500 requ√™tes
2. TTL sessions : 1h ‚Üí 24h

**Ces deux changements simples multiplieront votre capacit√© par 4-5 !**

Le reste des optimisations peut √™tre impl√©ment√© progressivement selon l'usage r√©el.

---

**Document cr√©√© le : 30 Novembre 2025**
